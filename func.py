# -*- coding: utf-8 -*-
"""DARNN_V_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q4_VqIzG2l4CGO6beH7IBHbgRjaLOOnN

# **Import Libraries**
"""
from func import *
import torch
from torch import nn
import pandas as pd
import random
from torch.utils import data
import time
from torch.nn import functional as F
import matplotlib.pyplot as plt
import numpy as np
from sklearn import preprocessing
import torch.optim.lr_scheduler as lr_scheduler
import json

from IPython.display import set_matplotlib_formats
# %matplotlib inline
from IPython import display


class Animator:
    """For plotting data in animation.
    #used in training loop
    """

    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,
                 ylim=None, xscale='linear', yscale='linear',
                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,
                 figsize=(7.5, 5.5), set_ylabel=False):
        # Incrementally plot multiple lines
        if legend is None:
            legend = []
        use_svg_display()
        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)
        if nrows * ncols == 1:
            self.axes = [self.axes, ]
        # Use a lambda function to capture arguments
        self.config_axes = lambda: set_axes(self.axes[
            0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend, set_ylabel)
        self.X, self.Y, self.fmts = None, None, fmts

    def add(self, x, y):
        # Add multiple data points into the figure
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        if not hasattr(x, "__len__"):
            x = [x] * n
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)
        self.axes[0].cla()
        for x, y, fmt in zip(self.X, self.Y, self.fmts):

            self.axes[0].plot(np.arange(len(x)), y, fmt)
            self.config_axes()
            set_xlabel(self.axes[0], x)
            plt.tight_layout()
            plt.savefig(f'figs/foo_{len(x)}.png')

        display.display(self.fig)
        display.clear_output(wait=True)


def use_svg_display():
    """Use the svg format to display a plot in Jupyter."""
    set_matplotlib_formats('svg')


def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend, set_ylabel):
    """Set the axes for matplotlib."""
    axes.set_xlabel(xlabel)
    axes.set_ylabel(ylabel)
    axes.set_xscale(xscale)
    axes.set_yscale(yscale)
    axes.set_xlim(xlim)
    axes.set_ylim(ylim)
    if set_ylabel:
        axes.set_yticks([-1, -0.6, -0.2, 0.2, 0.6, 1])
        axes.set_yticklabels(['None', 'D0', 'D1', 'D2', 'D3', 'D4'])

    if legend:
        axes.legend(legend)
    axes.grid()

def set_xlabel(axes, x):
    axes.set_xticks(np.arange(len(x)))
    date_time = [f"{ts.year}/{ts.month}/{ts.day}" for ts in x]
    axes.set_xticklabels(date_time, rotation=45)



class Accumulator:
    """For accumulating sums over `n` variables.
    Used in traing loop for accumulating the loss
    """

    def __init__(self, n):
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]


class Timer:
    """Record multiple running times.    
    """

    def __init__(self):
        self.times = []
        self.start()

    def start(self):
        """Start the timer."""
        self.tik = time.time()

    def stop(self):
        """Stop the timer and record the time in a list."""
        self.times.append(time.time() - self.tik)
        return self.times[-1]

    def avg(self):
        """Return the average time."""
        return sum(self.times) / len(self.times)

    def sum(self):
        """Return the sum of time."""
        return sum(self.times)

    def cumsum(self):
        """Return the accumulated time."""
        return np.array(self.times).cumsum().tolist()


def get_time_series_inputs(df, col_list, L=4, index_start=0):

    df1 = df[col_list].iloc[index_start:index_start + L]
    output = []
    for col in col_list:
        output.append(list(df1[col].values))

    return torch.tensor(output, dtype=torch.float32)


def seq_data_iter_random(feature, label, batch_size, num_steps):
    """Generate a minibatch of subsequences using random sampling."""
    # Start with a random offset (inclusive of `num_steps - 1`) to partition a
    # sequence
    start_point = random.randint(0, num_steps - 1)
    feature = feature[start_point:]
    label = label[start_point:]
    # Subtract 1 since we need to account for labels
    num_subseqs = (len(feature) - 1) // num_steps
    # The starting indices for subsequences of length `num_steps`
    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))
    # In random sampling, the subsequences from two adjacent random
    # minibatches during iteration are not necessarily adjacent on the
    # original sequence
    random.shuffle(initial_indices)

    def data(pos, longdata):
        # Return a sequence of length `num_steps` starting from `pos`
        return longdata[pos:pos + num_steps]

    num_batches = num_subseqs // batch_size
    for i in range(0, batch_size * num_batches, batch_size):
        # Here, `initial_indices` contains randomized starting indices for
        # subsequences
        initial_indices_per_batch = initial_indices[i:i + batch_size]
        X = [data(j, feature) for j in initial_indices_per_batch]
        Y = [data(j, label) for j in initial_indices_per_batch]
        yield torch.cat(X, dim=0).reshape(len(X), len(X[0]), -1), torch.cat(Y, dim=0).reshape(len(Y), len(Y[0]), -1)


def seq_data_iter_sequential(feature, label, batch_size, num_steps):
    """Generate a minibatch of subsequences using sequential partitioning."""
    # Start with a random offset to partition a sequence
    # offset = random.randint(0, num_steps)
    offset = 0
    num_tokens = ((len(feature) - offset - 1) // batch_size) * batch_size
    Xs = feature[offset:offset + num_tokens]
    Ys = label[offset:offset + num_tokens]

    dimen = Xs.shape[1]
    dimen_Y = Ys.shape[1]
    Xs, Ys = Xs.reshape(
        batch_size, -1, dimen), Ys.reshape(batch_size, -1, dimen_Y)

    num_batches = Xs.shape[1] // num_steps
    # for i in range(0, num_steps * num_batches, num_steps):
    for i in range(0, num_steps * num_batches, 1):
        # print(f"i: {i}")
        X = Xs[:, i:i + num_steps]
        Y = Ys[:, i:i + num_steps]
        yield X, Y


def batching_data(X):
    """the return shape will be (time_step, batch, features)"""
    Z = []
    for i in range(X.shape[1]):
        Z.append(X[:, i, :])
    return torch.cat(Z, dim=0).reshape(X.shape[1], X.shape[0], -1)


def try_gpu(i=0):
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:{i}')
    return torch.device('cpu')


class SeqDataLoader:
    """An iterator to load sequence data."""

    def __init__(self, my_seq1, my_seq2, batch_size, num_steps, use_random_iter):
        if use_random_iter:
            self.data_iter_fn = seq_data_iter_random
        else:
            self.data_iter_fn = seq_data_iter_sequential

        self.my_seq1, self.my_seq2 = my_seq1, my_seq2
        self.batch_size, self.num_steps = batch_size, num_steps

    def __iter__(self):
        return self.data_iter_fn(self.my_seq1, self.my_seq2, self.batch_size, self.num_steps)


def load_data_time_series(my_seq1, my_seq2, batch_size, num_steps,
                          use_random_iter=False):
    """Return the iterator"""
    data_iter = SeqDataLoader(
        my_seq1, my_seq2, batch_size, num_steps, use_random_iter)
    return data_iter


def grad_clipping(net, theta):
    """Clip the gradient."""
    if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(sum(torch.sum((p.grad**2)) for p in params))

    if norm > theta:
        for param in params:
            param.grad[:] *= theta / norm


def train_epoch(net, train_iter, loss, updater, device, use_random_iter):
    """Train a net within one epoch."""
    state_1, state_2, timer = None, None, Timer()
    metric = Accumulator(2)  # Sum of training loss, no. of sequences

    for X, Y in train_iter:

        if state_1 is None or state_2 is None or use_random_iter:
            # Initialize `state` when either it is the first iteration or
            # using random sampling
            state_1, state_2 = net.begin_state(
                batch_size=X.shape[0], device=device)

        y = Y[:, -1, :]
        X, Y = X.to(device), Y.to(device)

        # make it as num_step, batch_size*feature
        X, Y = batching_data(X), batching_data(Y)
        y_hat, state = net((X, Y), state_1, state_2)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.backward()
            grad_clipping(net, 1)
            updater.step()
        else:
            l.backward()
            grad_clipping(net, 1)
            # Since the `mean` function has been invoked
            updater(batch_size=1)
        metric.add(l * y.numel(), y.numel())

    return metric[0] / metric[1], metric[1]


def train(net, train_iter, test_iter, lr, num_epochs, device,
          use_random_iter=False):
    """Train a model"""
    loss = nn.MSELoss()
    animator = Animator(xlabel='epoch', ylabel='MSE Loss',
                        legend=['train loss', 'validation loss'], xlim=[10, num_epochs])

    if isinstance(net, nn.Module):
        updater = torch.optim.Adam(net.parameters(), lr)

    else:
        updater = torch.optim.Adam(net.params, lr)

    valid_min_error = 1e3  # set the initial validation error to a large value
    for epoch in range(num_epochs):
        train_loss, num_train_sample = train_epoch(net, train_iter, loss, updater, device,
                                                   use_random_iter)
        validation_loss, num_valid_sample = evaluate_model(
            net, test_iter, loss, device, use_random_iter)

        # save the params in the case of finding min error every other 50 epoches
        if epoch > 50:
            if validation_loss < valid_min_error:
                valid_min_error = validation_loss
                opt_params = net.params

        if (epoch + 1) % 10 == 0:
            print(f"train loss: {train_loss}, validation loss: {validation_loss}")
            animator.add(epoch + 1, [train_loss, validation_loss])
    return valid_min_error, opt_params


def evaluate_model(net, test_iter, loss, device, use_random_iter):
    """Test the model on test set"""
    state_1, state_2, timer = None, None, Timer()

    if isinstance(net, torch.nn.Module):
        net.eval()  # Set the model to evaluation mode

    metric = Accumulator(2)  # Sum of training loss, no. of tokens

    with torch.no_grad():
        for X, Y in test_iter:

            if state_1 is None or state_2 is None or use_random_iter:
                # Initialize `state` when either it is the first iteration or
                # using random sampling
                state_1, state_2 = net.begin_state(
                    batch_size=X.shape[0], device=device)

            y = Y[:, -1, :]
            X, Y = X.to(device),  Y.to(device)
            # make it as num_step, batch_size*feature
            X, Y = batching_data(X), batching_data(Y)
            y_hat, state = net((X, Y), state_1, state_2)
            l = loss(y_hat, y)
            metric.add(l * y.numel(), y.numel())

    return metric[0] / metric[1], metric[1]


def test(net, test_iter, device,
         use_random_iter=False):
    """Test a model"""
    loss = nn.MSELoss()
    ppl, acc = evaluate_model(net, test_iter, loss, device, use_random_iter)
    print(f"loss: {ppl}")


def get_lstm_params(num_exoc, num_hiddens_1, num_hiddens_2, device):
    num_inputs = num_exoc
    num_outputs = 1

    def normal(shape):
        return torch.randn(size=shape, device=device) * 0.01

    def three():
        return (normal(
            (num_inputs, num_hiddens_1)), normal((num_hiddens_1, num_hiddens_1)),
            torch.zeros(num_hiddens_1, device=device))

    def three_2():
        return (normal(
            (num_outputs, num_hiddens_2)), normal((num_hiddens_2, num_hiddens_2)),
            torch.zeros(num_hiddens_2, device=device))
    # first lstm
    W_xi, W_hi, b_i = three()  # Input gate parameters
    W_xf, W_hf, b_f = three()  # Forget gate parameters
    W_xo, W_ho, b_o = three()  # Output gate parameters
    W_xc, W_hc, b_c = three()  # Candidate memory cell parameters

    # second lstm
    W_hhi, W_di, b_id = three_2()  # Input gate parameters
    W_hhf, W_df, b_fd = three_2()  # Forget gate parameters
    W_hho, W_do, b_od = three_2()  # Output gate parameters
    W_hhc, W_dc, b_cd = three_2()  # Candidate memory cell parameters

    # Output layer parameters
    W_hq = normal((num_hiddens_1 + num_hiddens_2, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)

    # input attention layer
    U_ex = normal((num_inputs, num_inputs))
    v_e = normal((1, num_inputs))
    W_e = normal((2*num_hiddens_1, num_inputs))
    b_e = torch.zeros(num_outputs, device=device)

    # Temporal attention layer
    U_dx = normal((num_hiddens_1, num_hiddens_1))
    v_d = normal((1, num_hiddens_1))
    W_d = normal((2*num_hiddens_2, num_hiddens_1))
    b_d = torch.zeros(num_outputs, device=device)

    # for matching with decoder input
    W_hat = normal((num_hiddens_1 + 1, num_outputs))
    b_hat = torch.zeros(num_outputs, device=device)

    # Attach gradients
    params = [
        W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
        W_hq, b_q,
        U_ex, W_e, b_e, v_e,
        U_dx, W_d, b_d, v_d,
        W_hhi, W_di, b_id, W_hhf, W_df, b_fd, W_hho, W_do, b_od, W_hhc, W_dc, b_cd,
        W_hat, b_hat]
    for param in params:
        param.requires_grad_(True)
    return params


def init_lstm_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device),
            torch.zeros((batch_size, num_hiddens), device=device))


def lstm(inputs, state_1, state_2, params):
    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q, U_ex, W_e, b_e, v_e,
     U_dx, W_d, b_d, v_d, W_hhi, W_di, b_id, W_hhf, W_df, b_fd, W_hho, W_do, b_od, W_hhc, W_dc, b_cd,
     W_hat, b_hat] = params

    (H, C) = state_1
    (D, S) = state_2
    outputs = []

    # iterate through time steps
    for i, (X, Y) in enumerate(zip(inputs[0], inputs[1])):

        # input attention output
        E = torch.tanh((X @ U_ex)+(torch.cat((H, C), dim=1) @ W_e) + b_e) * v_e
        m = nn.Softmax(dim=1)
        X = m(E) * X

        # Encoder LSTM - iterates through time step
        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)
        C = F * C + I * C_tilda
        H = O * torch.tanh(C)

        # Temporal Attn output
        E1 = torch.tanh((H @ U_dx)+(torch.cat((D, S), dim=1) @ W_d) + b_d) * v_d
        H_prime = m(E1) * H

        # for matching with input of decoder
        Y_hat = (torch.cat((H_prime, Y), dim=1) @ W_hat) + b_hat

        # Decoder LSTM
        I_prime = torch.sigmoid((Y_hat @ W_hhi) + (D @ W_di) + b_id)
        F_prime = torch.sigmoid((Y_hat @ W_hhf) + (D @ W_df) + b_fd)
        O_prime = torch.sigmoid((Y_hat @ W_hho) + (D @ W_do) + b_od)
        S_tilda = torch.tanh((Y_hat @ W_hhc) + (D @ W_dc) + b_cd)
        S = F_prime * S + I_prime * S_tilda
        D = O_prime * torch.tanh(S)

        # only when we are at step T-1
        if i == inputs[0].shape[0] - 2:
            Y_T = (torch.cat((D, H_prime), dim=1) @ W_hq) + b_q
            return Y_T, (H, D)


class RNNModelScratch:
    """A RNN Model implemented from scratch."""

    def __init__(self, num_exog, num_hiddens_1, num_hiddens_2, device, get_params,
                 init_state, forward_fn, is_train=True):
        self.num_exog, self.num_hiddens_1, self.num_hiddens_2 = num_exog, num_hiddens_1, num_hiddens_2

        if is_train:
            self.params = get_params(
                num_exog, num_hiddens_1, num_hiddens_2, device)
        else:
            self.params = get_params

        self.init_state, self.forward_fn = init_state, forward_fn

    def __call__(self, X, state_1, state_2):
        return self.forward_fn(X, state_1, state_2, self.params)

    def begin_state(self, batch_size, device):
        return (self.init_state(batch_size, self.num_hiddens_1, device),
                self.init_state(batch_size, self.num_hiddens_2, device))


def predict_test(data, net, test_iter, device, optim_thr, use_random_iter=False):
    """Test the model on test set"""
    state_1, state_2, timer = None, None, Timer()

    animator = Animator(xlabel='Date', ylabel='Drought Level',
                        legend=['True Value', 'Predicted Value'], figsize=(9.5, 7.5), set_ylabel=True)

    if isinstance(net, torch.nn.Module):
        net.eval()  # Set the model to evaluation mode

    if state_1 is None or state_2 is None or use_random_iter:
        # Initialize `state` when either it is the first iteration or
        # using random sampling
        state_1, state_2 = net.begin_state(batch_size=1, device=device)

    idx = 0
    with torch.no_grad():
        for X, Y in test_iter:

            y = Y[:, -1, :]
            X, Y = X.to(device),  Y.to(device)
            # make it as num_step, batch_size*feature
            X, Y = batching_data(X), batching_data(Y)
            y_hat, state = net((X, Y), state_1, state_2)

            animator.add(data.index[idx], [y, level_conv(y_hat[0][0].item(
            ), beta_0=-0.8, beta_1=-0.4, beta_2=0, beta_3=0.4, beta_4=optim_thr)])
            idx += 1

    return y_hat


def threshold_set(L_3_4, L_4_3, p_d_3=0.054, p_d_4=0.021, sigma=0.1):
    """
    used in risk management

    -L_3_4: the loss if we mix D3 with D4
    -L_4_3: the loss if we mix D4 with D3
    -p_d_3: the frequency of drought level D3
    -p_d_4: the frequency of drought level D4
    """
    T_l = np.log(L_3_4/L_4_3)
    T_p = np.log(p_d_3/p_d_4)
    return 0.8 - 2.5 * (sigma ** 2) * (T_l - T_p)


def level_conv(x, beta_0=-0.8, beta_1=-0.4, beta_2=0, beta_3=0.4, beta_4=0.8):
    """
    used to convert the continuous value of regression into drought level
    """
    if x < beta_0:
        return -1
    elif x >= beta_0 and x < beta_1:
        return -0.6
    elif x >= beta_1 and x < beta_2:
        return -0.2
    elif x >= beta_2 and x < beta_3:
        return 0.2
    elif x >= beta_3 and x < beta_4:
        return 0.6
    else:
        return 1
